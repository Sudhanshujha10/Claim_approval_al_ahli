diff --git a/.env.example b/.env.example
new file mode 100644
index 0000000..d674116
--- /dev/null
+++ b/.env.example
@@ -0,0 +1,14 @@
+# Backend API Environment Variables
+# Copy this file to .env and fill in your actual values
+
+# OpenAI API Key (required for AI validation)
+OPENAI_API_KEY=sk-your-openai-api-key-here
+
+# Server Port (default: 3001)
+PORT=3001
+
+# Python Parser URL (if using Docling service)
+PYTHON_PARSER_URL=http://localhost:5000
+
+# Node Environment
+NODE_ENV=development
diff --git a/.gitignore b/.gitignore
index 7fb3d12..9d06c67 100644
--- a/.gitignore
+++ b/.gitignore
@@ -19,9 +19,10 @@ pnpm-debug.log*
 .vscode/
 .idea/
 
-# Env
+# Env (but allow .env.example)
 .env
 .env.*
+!.env.example
 
 # Husky
 .husky/_/
diff --git a/DEPLOY.md b/DEPLOY.md
new file mode 100644
index 0000000..7d69cba
--- /dev/null
+++ b/DEPLOY.md
@@ -0,0 +1,33 @@
+# üöÄ Quick Deployment Guide
+
+## Step 1: Deploy Backend to Render
+
+1. Go to https://dashboard.render.com
+2. Click "New +" ‚Üí "Web Service"
+3. Connect GitHub repo: `Sudhanshujha10/Claim_approval_al_ahli`
+4. Configure:
+   - Build: `npm install`
+   - Start: `node api/server.js`
+   - Add env var: `OPENAI_API_KEY=your-key`
+5. Copy the deployed URL (e.g., `https://qlm-api.onrender.com`)
+
+## Step 2: Deploy Frontend to Vercel
+
+Run these commands:
+
+```bash
+# Set backend URL (use YOUR Render URL from Step 1)
+echo "VITE_API_URL=https://your-render-url.onrender.com" > .env.production
+
+# Build
+npm run build
+
+# Deploy
+vercel --prod
+```
+
+## Done! üéâ
+
+Your app is live at the Vercel URL shown after deployment.
+
+**Note:** First request to Render backend may be slow (cold start on free tier).
diff --git a/VERCEL_DEPLOYMENT.md b/VERCEL_DEPLOYMENT.md
new file mode 100644
index 0000000..65793a4
--- /dev/null
+++ b/VERCEL_DEPLOYMENT.md
@@ -0,0 +1,183 @@
+# üöÄ Vercel Deployment Guide
+
+## ‚ö†Ô∏è Important Notes
+
+### **Vercel Limitations for This Project:**
+
+1. **File Storage:** Vercel serverless functions have **read-only filesystem**
+   - Cannot store uploaded PDFs permanently
+   - Cannot modify `claims.json` directly
+   - **Solution:** Need external storage (AWS S3, Vercel Blob, or Database)
+
+2. **Serverless Timeout:** 10 seconds on free tier
+   - AI validation might timeout
+   - **Solution:** Use Vercel Pro ($20/month) for 60s timeout
+
+3. **Python Parser:** Cannot run Python service on Vercel
+   - **Solution:** Deploy Python parser separately (Render/Railway) or use OpenAI Vision API only
+
+---
+
+## üéØ Recommended Architecture for Vercel
+
+### **Option A: Vercel + External Storage (Recommended)**
+```
+Frontend (Vercel) ‚Üí API (Vercel Serverless) ‚Üí Storage (Vercel Blob/S3)
+                                             ‚Üí Database (MongoDB Atlas/Supabase)
+```
+
+### **Option B: Hybrid Deployment**
+```
+Frontend (Vercel Static)
+Backend API (Render/Railway) ‚Üê Better for file storage
+Python Parser (Render)
+```
+
+---
+
+## üöÄ Quick Deploy to Vercel (Frontend Only)
+
+If you want to deploy just the frontend for now:
+
+### 1. Install Vercel CLI
+```bash
+npm i -g vercel
+```
+
+### 2. Login to Vercel
+```bash
+vercel login
+```
+
+### 3. Deploy
+```bash
+vercel --prod
+```
+
+### 4. Set Environment Variables in Vercel Dashboard
+- `OPENAI_API_KEY` - Your OpenAI API key
+- `VITE_API_URL` - Your backend API URL (if separate)
+
+---
+
+## üì¶ Full Deployment Steps (With Backend)
+
+### **Prerequisites:**
+1. Vercel account
+2. External storage solution (choose one):
+   - **Vercel Blob Storage** (easiest, paid)
+   - **AWS S3** (flexible, pay-as-you-go)
+   - **MongoDB Atlas** (free tier available)
+
+### **Step 1: Modify Code for Serverless**
+
+#### Update API to use external storage:
+- Replace file system writes with Vercel Blob/S3
+- Replace `claims.json` with database (MongoDB/Supabase)
+
+#### Example: Using Vercel Blob
+```javascript
+import { put, list } from '@vercel/blob';
+
+// Upload PDF
+const blob = await put('claim-pdfs/file.pdf', fileBuffer, {
+  access: 'public',
+});
+```
+
+### **Step 2: Update Environment Variables**
+Create `.env.production`:
+```
+OPENAI_API_KEY=your_key_here
+BLOB_READ_WRITE_TOKEN=your_vercel_blob_token
+MONGODB_URI=your_mongodb_connection_string
+```
+
+### **Step 3: Deploy**
+```bash
+vercel --prod
+```
+
+---
+
+## üîß Alternative: Deploy Backend Separately
+
+### **Better Approach for This Project:**
+
+1. **Frontend ‚Üí Vercel** (Static Site)
+   ```bash
+   npm run build
+   vercel --prod
+   ```
+
+2. **Backend ‚Üí Render** (Free Tier)
+   - Persistent file storage
+   - No timeout issues
+   - Can run Python parser
+
+3. **Update Frontend API URL:**
+   ```typescript
+   // src/lib/api.ts
+   const API_URL = import.meta.env.VITE_API_URL || 'https://your-backend.onrender.com';
+   ```
+
+---
+
+## üìã What You Need to Decide:
+
+### **Option 1: Vercel Only (Requires Code Changes)**
+- ‚úÖ Single platform
+- ‚ùå Need external storage ($)
+- ‚ùå Need code refactoring
+- ‚ùå 10s timeout limit
+
+### **Option 2: Vercel Frontend + Render Backend (Recommended)**
+- ‚úÖ No code changes needed
+- ‚úÖ Free tier available
+- ‚úÖ File storage works
+- ‚úÖ No timeout issues
+- ‚úÖ Python parser works
+- ‚ùå Two platforms to manage
+
+---
+
+## üéØ My Recommendation
+
+**Deploy Frontend to Vercel + Backend to Render:**
+
+### **Why?**
+1. Your app needs file storage (PDFs, claims.json)
+2. AI validation can take >10 seconds
+3. Python parser needs persistent service
+4. Minimal code changes required
+
+### **Steps:**
+1. Deploy backend to Render (5 minutes)
+2. Deploy frontend to Vercel (2 minutes)
+3. Update API URL in frontend
+4. Done! ‚úÖ
+
+---
+
+## üöÄ Quick Start Commands
+
+### **Deploy Frontend Only (Vercel):**
+```bash
+npm run build
+vercel --prod
+```
+
+### **Deploy Full Stack (Render):**
+```bash
+# Will provide Render deployment steps if you choose this option
+```
+
+---
+
+## ‚ùì What Would You Like to Do?
+
+1. **Deploy frontend only to Vercel** (backend stays local)
+2. **Deploy frontend to Vercel + backend to Render** (recommended)
+3. **Refactor code for Vercel serverless** (requires storage setup)
+
+Let me know your choice and I'll proceed!
diff --git a/render.yaml b/render.yaml
new file mode 100644
index 0000000..41367d8
--- /dev/null
+++ b/render.yaml
@@ -0,0 +1,30 @@
+services:
+  # Backend API Service
+  - type: web
+    name: qlm-claims-api
+    env: node
+    region: oregon
+    plan: free
+    buildCommand: npm install
+    startCommand: node api/server.js
+    envVars:
+      - key: NODE_ENV
+        value: production
+      - key: PORT
+        value: 3001
+      - key: OPENAI_API_KEY
+        sync: false
+    healthCheckPath: /api/claims
+
+  # Python Parser Service (Optional - if using Docling)
+  - type: web
+    name: qlm-claims-parser
+    env: python
+    region: oregon
+    plan: free
+    buildCommand: cd python-parser && pip install -r requirements.txt
+    startCommand: cd python-parser && python app.py
+    envVars:
+      - key: PORT
+        value: 5000
+    healthCheckPath: /health
diff --git a/src/lib/api.ts b/src/lib/api.ts
index 4435122..2b115d0 100644
--- a/src/lib/api.ts
+++ b/src/lib/api.ts
@@ -13,7 +13,8 @@ export interface ValidateResp {
   error?: string;
 }
 
-const BASE_URL = ""; // Vite proxy handles /api/* in dev
+// Use environment variable for production, empty string for dev (Vite proxy)
+const BASE_URL = import.meta.env.VITE_API_URL || "";
 
 export async function uploadClaimFiles(files: File[]): Promise<UploadResp> {
   const fd = new FormData();
diff --git a/vercel.json b/vercel.json
new file mode 100644
index 0000000..222fe67
--- /dev/null
+++ b/vercel.json
@@ -0,0 +1,9 @@
+{
+  "version": 2,
+  "buildCommand": "npm run build",
+  "outputDirectory": "dist",
+  "rewrites": [
+    { "source": "/api/(.*)", "destination": "/api/$1" },
+    { "source": "/(.*)", "destination": "/index.html" }
+  ]
+}
